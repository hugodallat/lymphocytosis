{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advisory-ideal",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from datetime import date\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import torch\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-barrel",
   "metadata": {},
   "source": [
    "# Description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>LYMPH_COUNT</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P26</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>11.2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P183</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>12.8</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P89</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>9.6</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  LABEL GENDER  LYMPH_COUNT  AGE\n",
       "0   P26      1      M         11.2   88\n",
       "1  P183      1      M         12.8   79\n",
       "2   P89      1      M          9.6   86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clinical_annotation.csv')\n",
    "df['AGE'] = df['DOB'].apply(lambda x : date.today().year-int(x[-4:]))\n",
    "df = df.drop(columns = ['Unnamed: 0','DOB'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "racial-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['LABEL']!=-1]\n",
    "test_df = df[df['LABEL']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "geographic-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "     N          age %sexF  LYMPH_COUNT\n",
      "0   50  55.3 ± 19.6  52.0    5.0 ± 1.0\n",
      "1  113  76.2 ± 12.0  47.8  35.9 ± 53.3\n",
      "Test\n",
      "     N          age %sexF  LYMPH_COUNT\n",
      "-1  42  66.7 ± 19.5  42.9  24.4 ± 43.6\n"
     ]
    }
   ],
   "source": [
    "def characteristics_table(df):\n",
    "    \"\"\"Creates a DataFrame that summarizes the characteristics of the DataFrame df\"\"\"\n",
    "    diagnoses = np.unique(df.LABEL.values)\n",
    "    population_df = pd.DataFrame(index=diagnoses,\n",
    "                                columns=['N', 'age', '%sexF', 'LYMPH_COUNT'])\n",
    "\n",
    "    \n",
    "    for label in population_df.index.values:\n",
    "        diagnosis_df = df[df.LABEL == label]\n",
    "        population_df.loc[label, 'N'] = len(diagnosis_df)\n",
    "        # Age\n",
    "        mean_age = np.mean(diagnosis_df.AGE)\n",
    "        std_age = np.std(diagnosis_df.AGE)\n",
    "        population_df.loc[label, 'age'] = '%.1f ± %.1f' % (mean_age, std_age)\n",
    "        # Sex\n",
    "        population_df.loc[label, '%sexF'] = round((len(diagnosis_df[diagnosis_df.GENDER == 'F']) / len(diagnosis_df)) * 100, 1)\n",
    "        # Lymph count\n",
    "        mean_MMS = np.mean(diagnosis_df.LYMPH_COUNT)\n",
    "        std_MMS = np.std(diagnosis_df.LYMPH_COUNT)\n",
    "        population_df.loc[label, 'LYMPH_COUNT'] = '%.1f ± %.1f' % (mean_MMS, std_MMS)\n",
    "\n",
    "    return population_df\n",
    "\n",
    "print(\"Train\")\n",
    "population_train_df = characteristics_table(train_df)\n",
    "print(population_train_df)\n",
    "print(\"Test\")\n",
    "population_test_df = characteristics_table(test_df)\n",
    "print(population_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-shield",
   "metadata": {},
   "source": [
    "**The train and test set are balanced. Now we must create validation sets.\\\n",
    "A high lymphocyte count is strongly correlated with cancer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chicken-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "    N          age %sexF  LYMPH_COUNT\n",
      "0  39  53.5 ± 19.4  53.8    5.0 ± 1.0\n",
      "1  85  75.7 ± 12.4  42.4  34.1 ± 47.7\n",
      "Validation\n",
      "    N          age %sexF  LYMPH_COUNT\n",
      "0  11  61.5 ± 19.1  45.5    5.0 ± 1.0\n",
      "1  28  77.8 ± 10.7  64.3  41.3 ± 67.3\n"
     ]
    }
   ],
   "source": [
    "split_df = train_df\n",
    "msk = np.random.rand(len(train_df)) < 0.75\n",
    "train_df = split_df[msk]\n",
    "val_df = split_df[~msk]\n",
    "print(\"Train\")\n",
    "population_train_df = characteristics_table(train_df)\n",
    "print(population_train_df)\n",
    "print(\"Validation\")\n",
    "population_val_df = characteristics_table(val_df)\n",
    "print(population_val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-assembly",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nuclear-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lympho_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path_images, df, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path_images: (str) path to the images origin directory.\n",
    "            data_df: (DataFrame) list of subjects used.\n",
    "            transform: Optional, transformations applied to the tensor\n",
    "        \"\"\"\n",
    "        self.path_images = path_images\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.list_patients = df['ID'].tolist()\n",
    "        self.lymph_count = df['LYMPH_COUNT'].tolist()\n",
    "        self.age = df['AGE'].tolist()\n",
    "        self.labels = df['LABEL'].tolist()\n",
    "        self.img_dict = {idx : {'label' : self.labels[idx],\n",
    "                           'age' : self.age[idx],\n",
    "                           'lymph_count' : self.lymph_count[idx],\n",
    "                            'patient' : self.list_patients[idx],\n",
    "                           'images_path' : [path_images + '/' + patient + '/' + img_path for img_path in os.listdir(path_images + '/' + patient)]} for idx,patient in enumerate(self.list_patients)}\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly.\n",
    "        \"\"\"\n",
    "#         image = imageio.imread(image_path).astype(np.uint8)[...,None]\n",
    "        image = Image.open(image_path)\n",
    "        # Stack image on itself 3 times to simulate RGB image (3 channels required for model's input)  \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx: (int) the index of the subject whom data is loaded.\n",
    "        Returns:\n",
    "            sample: (dict) corresponding data described by the following keys:\n",
    "                image: (Tensor) Images of the patient's blood cells image in a tensor\n",
    "                label: (int) the diagnosis code (0 for reactive or 1 for cancerous)\n",
    "                participant_id: (str) ID of the participant \n",
    "                lymph_count : (int) Lymphocyte concentration in patient's blood\n",
    "                age : (int) Patient's age\n",
    "        \"\"\"\n",
    "        images = [self.transform(self.load_image(image)) for image in self.img_dict[idx]['images_path']]\n",
    "        images = [transforms.ToTensor()(image).unsqueeze_(0) for image in images]\n",
    "        images = torch.cat(images,axis=0)\n",
    "        \n",
    "        age = torch.Tensor([self.img_dict[idx]['age']])\n",
    "        lymph_count = torch.Tensor([self.img_dict[idx]['lymph_count']])\n",
    "        patient = self.img_dict[idx]['patient']\n",
    "        label = torch.Tensor([self.img_dict[idx]['label']])\n",
    "        \n",
    "        sample = {'images' : images,\n",
    "                  'lymph_count' : lymph_count,\n",
    "                  'patient' : patient,\n",
    "                  'label' : label,\n",
    "                  'age' : age}\n",
    "        return sample\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "important-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = r'C:\\Users\\Hugo\\Desktop\\MVA\\S2\\DLMI\\Kaggle\\trainset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "manual-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Lympho_Dataset(path_images, train_df, transform = RandomHorizontalFlip(p=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thick-rabbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 224, 224])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(0)['images'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-ethics",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-directory",
   "metadata": {},
   "source": [
    "##### All images are of shape (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "indie-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(21632, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 21632)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def get_outputs(self,images):\n",
    "        outputs = []\n",
    "        for i in range(images.size()[0]):\n",
    "            image = images[i][None,:,:,:]\n",
    "            output = self.forward(image)\n",
    "            outputs.append(output)\n",
    "#         print(torch.stack(outputs).size())\n",
    "        mean = torch.mean(torch.stack(outputs),axis=0)\n",
    "        return mean\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-turkish",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cutting-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "solved-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fn(batch):\n",
    "    elem = batch[0].keys()\n",
    "    return {key : torch.cat(gen_list(key, batch), axis=0) if key != 'name' else gen_list(key, batch) for key in elem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loading all the train images : 62.9752 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    test = batch\n",
    "print(f\"Time for loading all the train images : {round(time.time() - start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "numerical-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_input = train_data.__getitem__(0)['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adopted-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.9647, 0.9882, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "           [0.9765, 0.9882, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           [0.9804, 0.9882, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           ...,\n",
       "           [0.9882, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9882],\n",
       "           [0.9882, 0.9882, 0.9882,  ..., 0.9961, 0.9922, 0.9882],\n",
       "           [0.9804, 0.9882, 0.9882,  ..., 0.9961, 0.9922, 0.9882]],\n",
       "\n",
       "          [[0.9059, 0.8941, 0.8784,  ..., 0.8980, 0.9020, 0.8980],\n",
       "           [0.9059, 0.8863, 0.8824,  ..., 0.8980, 0.9020, 0.8941],\n",
       "           [0.8980, 0.8863, 0.8863,  ..., 0.8980, 0.9020, 0.8941],\n",
       "           ...,\n",
       "           [0.8941, 0.8980, 0.8980,  ..., 0.8980, 0.8980, 0.8941],\n",
       "           [0.8980, 0.8980, 0.8941,  ..., 0.9020, 0.8980, 0.8941],\n",
       "           [0.8941, 0.8980, 0.8941,  ..., 0.9020, 0.8980, 0.8941]],\n",
       "\n",
       "          [[0.7529, 0.7922, 0.8118,  ..., 0.7922, 0.7961, 0.7922],\n",
       "           [0.7647, 0.7804, 0.8039,  ..., 0.7922, 0.7961, 0.7882],\n",
       "           [0.7765, 0.7804, 0.7922,  ..., 0.7922, 0.7961, 0.7882],\n",
       "           ...,\n",
       "           [0.7843, 0.7882, 0.7882,  ..., 0.7882, 0.7882, 0.7843],\n",
       "           [0.7725, 0.7765, 0.7843,  ..., 0.7922, 0.7882, 0.7843],\n",
       "           [0.7490, 0.7725, 0.7843,  ..., 0.7922, 0.7882, 0.7843]]],\n",
       "\n",
       "\n",
       "         [[[0.9804, 0.9804, 0.9843,  ..., 0.9961, 0.9961, 0.9961],\n",
       "           [0.9804, 0.9804, 0.9843,  ..., 0.9961, 0.9961, 0.9961],\n",
       "           [0.9804, 0.9804, 0.9843,  ..., 0.9961, 0.9961, 0.9961],\n",
       "           ...,\n",
       "           [0.7490, 0.7490, 0.7451,  ..., 0.9725, 0.9725, 0.9804],\n",
       "           [0.7529, 0.7529, 0.7529,  ..., 0.9725, 0.9725, 0.9765],\n",
       "           [0.7529, 0.7529, 0.7529,  ..., 0.9804, 0.9725, 0.9725]],\n",
       "\n",
       "          [[0.8745, 0.8745, 0.8784,  ..., 0.8863, 0.8863, 0.8863],\n",
       "           [0.8745, 0.8745, 0.8784,  ..., 0.8863, 0.8863, 0.8863],\n",
       "           [0.8745, 0.8745, 0.8784,  ..., 0.8863, 0.8863, 0.8863],\n",
       "           ...,\n",
       "           [0.6078, 0.6078, 0.6039,  ..., 0.8706, 0.8706, 0.8784],\n",
       "           [0.6118, 0.6118, 0.6118,  ..., 0.8706, 0.8706, 0.8745],\n",
       "           [0.6078, 0.6118, 0.6118,  ..., 0.8784, 0.8706, 0.8706]],\n",
       "\n",
       "          [[0.7922, 0.7922, 0.7961,  ..., 0.8000, 0.8000, 0.8000],\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.8000, 0.8000, 0.8000],\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.8000, 0.8000, 0.8000],\n",
       "           ...,\n",
       "           [0.6627, 0.6549, 0.6431,  ..., 0.7804, 0.7804, 0.7882],\n",
       "           [0.6667, 0.6667, 0.6510,  ..., 0.7804, 0.7804, 0.7843],\n",
       "           [0.6745, 0.6667, 0.6510,  ..., 0.7882, 0.7804, 0.7804]]],\n",
       "\n",
       "\n",
       "         [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           ...,\n",
       "           [0.7686, 0.7686, 0.7569,  ..., 0.9922, 0.9961, 0.9961],\n",
       "           [0.7490, 0.7490, 0.7451,  ..., 0.9843, 0.9843, 0.9961],\n",
       "           [0.7490, 0.7490, 0.7529,  ..., 0.9843, 0.9843, 0.9882]],\n",
       "\n",
       "          [[0.8980, 0.8980, 0.8980,  ..., 0.9020, 0.9098, 0.9059],\n",
       "           [0.8980, 0.8980, 0.9020,  ..., 0.9020, 0.9098, 0.9059],\n",
       "           [0.8980, 0.8980, 0.9020,  ..., 0.9020, 0.9098, 0.9059],\n",
       "           ...,\n",
       "           [0.6392, 0.6392, 0.6275,  ..., 0.9098, 0.9020, 0.9020],\n",
       "           [0.6196, 0.6196, 0.6157,  ..., 0.9059, 0.9059, 0.9059],\n",
       "           [0.6196, 0.6196, 0.6118,  ..., 0.9059, 0.9059, 0.9098]],\n",
       "\n",
       "          [[0.7922, 0.7922, 0.7922,  ..., 0.7961, 0.7882, 0.7843],\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.7961, 0.7882, 0.7843],\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.7961, 0.7882, 0.7843],\n",
       "           ...,\n",
       "           [0.6667, 0.6667, 0.6549,  ..., 0.7882, 0.7922, 0.8000],\n",
       "           [0.6549, 0.6549, 0.6510,  ..., 0.7686, 0.7765, 0.7843],\n",
       "           [0.6471, 0.6549, 0.6510,  ..., 0.7608, 0.7686, 0.7804]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.9961, 0.9961, 1.0000,  ..., 0.9373, 0.9529, 0.9608],\n",
       "           [0.9961, 0.9961, 1.0000,  ..., 0.8627, 0.8784, 0.8902],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.8157, 0.8353, 0.8471],\n",
       "           ...,\n",
       "           [0.7725, 0.7647, 0.7529,  ..., 0.6941, 0.6902, 0.6941],\n",
       "           [0.7608, 0.7569, 0.7608,  ..., 0.7020, 0.6980, 0.6941],\n",
       "           [0.7529, 0.7451, 0.7490,  ..., 0.7137, 0.7020, 0.6980]],\n",
       "\n",
       "          [[0.8863, 0.8863, 0.8902,  ..., 0.8039, 0.8196, 0.8275],\n",
       "           [0.8863, 0.8863, 0.8902,  ..., 0.7216, 0.7451, 0.7569],\n",
       "           [0.8902, 0.8902, 0.8941,  ..., 0.6784, 0.6980, 0.7098],\n",
       "           ...,\n",
       "           [0.6353, 0.6157, 0.6078,  ..., 0.5490, 0.5412, 0.5451],\n",
       "           [0.6157, 0.6118, 0.6078,  ..., 0.5569, 0.5490, 0.5451],\n",
       "           [0.6157, 0.6000, 0.5922,  ..., 0.5686, 0.5529, 0.5490]],\n",
       "\n",
       "          [[0.8000, 0.8000, 0.8078,  ..., 0.7686, 0.7843, 0.7922],\n",
       "           [0.8000, 0.8000, 0.8078,  ..., 0.7216, 0.7373, 0.7490],\n",
       "           [0.8039, 0.8039, 0.8118,  ..., 0.7020, 0.7137, 0.7255],\n",
       "           ...,\n",
       "           [0.7216, 0.6980, 0.6745,  ..., 0.6196, 0.6235, 0.6275],\n",
       "           [0.6863, 0.6824, 0.6784,  ..., 0.6275, 0.6314, 0.6353],\n",
       "           [0.6431, 0.6314, 0.6353,  ..., 0.6392, 0.6431, 0.6392]]],\n",
       "\n",
       "\n",
       "         [[[0.6549, 0.6549, 0.6549,  ..., 1.0000, 1.0000, 0.9882],\n",
       "           [0.6549, 0.6549, 0.6549,  ..., 1.0000, 0.9961, 0.9882],\n",
       "           [0.6627, 0.6627, 0.6627,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           ...,\n",
       "           [0.7255, 0.7059, 0.7059,  ..., 0.9725, 0.9765, 0.9804],\n",
       "           [0.7569, 0.7255, 0.7137,  ..., 0.9686, 0.9686, 0.9765],\n",
       "           [0.7804, 0.7529, 0.7373,  ..., 0.9765, 0.9686, 0.9725]],\n",
       "\n",
       "          [[0.5176, 0.5176, 0.5176,  ..., 0.8824, 0.8784, 0.8667],\n",
       "           [0.5176, 0.5176, 0.5176,  ..., 0.8784, 0.8745, 0.8667],\n",
       "           [0.5137, 0.5137, 0.5137,  ..., 0.8784, 0.8784, 0.8745],\n",
       "           ...,\n",
       "           [0.6510, 0.6235, 0.6039,  ..., 0.8667, 0.8706, 0.8745],\n",
       "           [0.6549, 0.6157, 0.6039,  ..., 0.8627, 0.8627, 0.8706],\n",
       "           [0.6471, 0.6235, 0.6157,  ..., 0.8706, 0.8627, 0.8667]],\n",
       "\n",
       "          [[0.6039, 0.6039, 0.6039,  ..., 0.8000, 0.8000, 0.7961],\n",
       "           [0.6039, 0.6039, 0.6039,  ..., 0.8000, 0.7961, 0.7882],\n",
       "           [0.6039, 0.6039, 0.6039,  ..., 0.8000, 0.8000, 0.7961],\n",
       "           ...,\n",
       "           [0.6588, 0.6431, 0.6471,  ..., 0.7843, 0.7882, 0.7922],\n",
       "           [0.7059, 0.6706, 0.6588,  ..., 0.7804, 0.7804, 0.7882],\n",
       "           [0.7412, 0.7059, 0.6863,  ..., 0.7882, 0.7804, 0.7843]]],\n",
       "\n",
       "\n",
       "         [[[0.9765, 0.9804, 0.9765,  ..., 0.7647, 0.7333, 0.7373],\n",
       "           [0.9725, 0.9804, 0.9765,  ..., 0.7961, 0.7490, 0.7412],\n",
       "           [0.9686, 0.9765, 0.9725,  ..., 0.8745, 0.7843, 0.7412],\n",
       "           ...,\n",
       "           [0.7176, 0.7137, 0.7098,  ..., 0.9843, 0.9882, 0.9922],\n",
       "           [0.7176, 0.7098, 0.7176,  ..., 0.9882, 0.9882, 0.9882],\n",
       "           [0.7216, 0.7176, 0.7412,  ..., 0.9882, 0.9882, 0.9882]],\n",
       "\n",
       "          [[0.8745, 0.8784, 0.8745,  ..., 0.6039, 0.5804, 0.5804],\n",
       "           [0.8667, 0.8745, 0.8706,  ..., 0.6510, 0.6000, 0.5882],\n",
       "           [0.8627, 0.8706, 0.8667,  ..., 0.7451, 0.6471, 0.5922],\n",
       "           ...,\n",
       "           [0.5961, 0.5922, 0.5922,  ..., 0.8824, 0.8863, 0.8902],\n",
       "           [0.5961, 0.5882, 0.6000,  ..., 0.8863, 0.8863, 0.8863],\n",
       "           [0.6000, 0.5961, 0.6196,  ..., 0.8863, 0.8863, 0.8863]],\n",
       "\n",
       "          [[0.7765, 0.7804, 0.7843,  ..., 0.6588, 0.6627, 0.6745],\n",
       "           [0.7843, 0.7922, 0.7882,  ..., 0.6784, 0.6588, 0.6627],\n",
       "           [0.7961, 0.8039, 0.8000,  ..., 0.7176, 0.6706, 0.6431],\n",
       "           ...,\n",
       "           [0.6667, 0.6627, 0.6392,  ..., 0.7922, 0.7961, 0.8000],\n",
       "           [0.6667, 0.6588, 0.6471,  ..., 0.7961, 0.7961, 0.7961],\n",
       "           [0.6627, 0.6667, 0.6784,  ..., 0.7961, 0.7961, 0.7961]]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-netscape",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    Method used to test a CNN\n",
    "    \n",
    "    Args:\n",
    "        model: (nn.Module) the neural network\n",
    "        data_loader: (DataLoader) a DataLoader wrapping a MRIDataset\n",
    "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
    "    \n",
    "    Returns:\n",
    "        results_df: (DataFrame) the label predicted for every subject\n",
    "        results_metrics: (dict) a set of metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    data_loader.dataset.eval()\n",
    "    columns = [\"participant_id\", \"proba0\", \"proba1\",\n",
    "               \"true_label\", \"predicted_label\"]\n",
    "    results_df = pd.DataFrame(columns=columns)\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader, 0):\n",
    "            images, labels = data['image'].cuda(), data['label'].cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            probs = nn.Softmax(dim=1)(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            for idx, sub in enumerate(data['participant_id']):\n",
    "                row = [sub,\n",
    "                       probs[idx, 0].item(), probs[idx, 1].item(),\n",
    "                       labels[idx].item(), predicted[idx].item()]\n",
    "                row_df = pd.DataFrame([row], columns=columns)\n",
    "                results_df = pd.concat([results_df, row_df])\n",
    "\n",
    "    results_metrics = compute_metrics(results_df.true_label.values, results_df.predicted_label.values)\n",
    "    results_df.reset_index(inplace=True, drop=True)\n",
    "    results_metrics['mean_loss'] = total_loss / len(data_loader.dataset)\n",
    "    \n",
    "    return results_df, results_metrics\n",
    "\n",
    "\n",
    "def compute_metrics(ground_truth, prediction):\n",
    "    \"\"\"Computes the accuracy, sensitivity, specificity and balanced accuracy\"\"\"\n",
    "    tp = np.sum((prediction == 1) & (ground_truth == 1))\n",
    "    tn = np.sum((prediction == 0) & (ground_truth == 0))\n",
    "    fp = np.sum((prediction == 1) & (ground_truth == 0))\n",
    "    fn = np.sum((prediction == 0) & (ground_truth == 1))\n",
    "    \n",
    "    metrics_dict = dict()\n",
    "    metrics_dict['accuracy'] = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Sensitivity\n",
    "    if tp + fn != 0:\n",
    "        metrics_dict['sensitivity'] = tp / (tp + fn)\n",
    "    else:\n",
    "        metrics_dict['sensitivity'] = 0.0\n",
    "        \n",
    "    # Specificity\n",
    "    if fp + tn != 0:\n",
    "        metrics_dict['specificity'] = tn / (fp + tn)\n",
    "    else:\n",
    "        metrics_dict['specificity'] = 0.0\n",
    "        \n",
    "    metrics_dict['balanced_accuracy'] = (metrics_dict['sensitivity'] + metrics_dict['specificity']) / 2\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "settled-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-4)\n",
    "net = Net()\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "proved-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-3c253a63d630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        image_tensor = batch['images']\n",
    "        output = net.get_outputs(tensor_input)\n",
    "        loss = criterion(output,batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_track.append(loss.item())\n",
    "        print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-emergency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
